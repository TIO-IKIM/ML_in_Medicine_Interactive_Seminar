{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: \"An introduction to PyTorch\"\n",
    "\n",
    "From now on, we will be working with a Python package called PyTorch. Besides TensorFlow, it is the premier machine learning environment. It comes with a lot of features and a couple things that may trip up new users. We will try to slowly ease ourselves into using PyTorch.\n",
    "\n",
    "For all future tasks, try to figure out what it is you want to do in the jargon of Python/PyTorch and find the function(s) you need yourself. This may be slow at first, but it helps you get the hang of solving problems on your own. Try to say what you want as precisely as possible. Then google exactly that, in as few words as possible, and try to understand what you found and how it works. If you don't understand the solution you found, take it apart, execute only a part of it, experiment!\n",
    "\n",
    "If something still doesn't work, or the assignment doesn't make sense, feel free to ask the tutors, too. After all, that's why we're here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.1: \"Tensors\"\n",
    "\n",
    "The tensor sits at the heart of the PyTorch package. A tensor in machine learning is basically the same as an n-dimensional matrix. Under the hood, tensors work almost the same way as the numpy arrays we already know. However, tensors come with a couple of additional functionalities. Attached to each tensor is information about the data type it contains, the device it currently resides in (for example the regular memory, or the memory of a GPU), and most importantly information about its gradients. We will come back to the last bit later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# How do we make a tensor? Essentially the same as a numpy array.\n",
    "my_tensor = torch.tensor([1, 2, 3])\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In fact, we can even make a numpy array into a tensor:\n",
    "my_array = np.array([2, 3, 4, 5])\n",
    "my_tensor = torch.tensor(my_array)\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get back our numpy array from a tensor:\n",
    "my_array = my_tensor.numpy()\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors come with most of the same functionality as numpy arrays, such as\n",
    "# Knowing its own dimensions\n",
    "my_tensor = torch.zeros((1, 4))\n",
    "print(my_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposition\n",
    "print(my_tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "print(my_tensor.reshape((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "print(my_tensor.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations along an axis\n",
    "my_tensor = torch.tensor([[1, 2], [4, 3]])\n",
    "print(my_tensor.argmax(axis=0))\n",
    "print(my_tensor.argmax(axis=1))\n",
    "# and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occasionally, you will come across tensors with only one component.\n",
    "# These are still, technically, a sort of matrix. However, you can turn\n",
    "# them into just a regular scalar if need be:\n",
    "t = torch.tensor(1)\n",
    "print(t)\n",
    "print(t.item())\n",
    "\n",
    "# As you may have already noticed, the syntax of the tensor operations is\n",
    "# almost the same as that for numpy arrays, but not always exactly the same.\n",
    "# Don't worry - PyTorch is well-documented. If you know what you want,\n",
    "# you can find it on Google or their documentation website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors know where they currently live.\n",
    "# This attribute of a tensor is called 'device'.\n",
    "my_tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(my_tensor.device)\n",
    "\n",
    "# We can manually move tensors and other PyTorch objects around on devices.\n",
    "# We do so with the '.to' method. The method expects the name of the device\n",
    "# we send it to. This could be \"cpu\", \"cuda\", or something like \"cuda:0\".\n",
    "\n",
    "# 'cuda' is the name of the engine under the hood, so to speak, and when we\n",
    "# specify 'cuda' as the target device, our tensor is put into the memory of\n",
    "# a GPU. If we specify the number, we select the nth GPU specifically.\n",
    "my_tensor = my_tensor.to(\"cuda:0\")\n",
    "print(my_tensor.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.2: \"Image data\"\n",
    "\n",
    "We will be slinging some significant numbers of images around later, enough that we do not want to write the name of every image manually or look at all of them. Therefore, let's look at how we can start with an image on our disk and end up with a PyTorch tensor containing said image in our memory.\n",
    "\n",
    "For this purpose we have prepared some tutorial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "\n",
    "# Let's first load an image. For this purpose, we use PIL ('Pillow'), \n",
    "# which can read jpg or png images from the disk.\n",
    "with PIL.Image.open(\"../data/Clean_LiTS/train/volumes/volume-10_337.png\") as f:\n",
    "\n",
    "    # Now we grab the array from the image.\n",
    "    img_array = np.array(f, dtype = np.uint8)\n",
    "\n",
    "# Let's see what size our image is.\n",
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can already visualize the image using matplotlib\n",
    "plt.figure()\n",
    "plt.imshow(img_array)\n",
    "plt.xlim((0, 256))\n",
    "plt.ylim((0, 256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this course, we will primarily be working with a dataset named \"LiTS\". LiTS is shorthand for \"**Li**ver **T**umor **S**egmentation\". It contains computed tomography (CT) images, which are 3D volumes (X, Y, Z) reconstructed from measured x-ray absorption. These volumes consist of several hundred *slices* each. A slice is nothing more than a 2-dimensional (X, Y) grayscale image. In fact, the image above is one of the LiTS images. The goal in the LiTS challenge was to make a neural network accurately locate the liver in those images, as well as the tumors, if there were any.\n",
    "\n",
    "Later on, we will first try to classify the images into three categories: No Liver, Liver, and Liver Tumor. We will later also try to solve the segmentation challenge with our neural networks. \n",
    "\n",
    "For now, let's just figure out how to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make our plot look a little nicer.\n",
    "\n",
    "# Let us first load the image\n",
    "with PIL.Image.open(\"../data/Clean_LiTS/train/volumes/volume-10_337.png\") as f:\n",
    "    \n",
    "    # This time, we convert the image to grayscale immediately.\n",
    "    # It always was already grayscale of course, but had 3 channels - RGB.\n",
    "    f = f.convert(\"L\")\n",
    "\n",
    "    # We again grab the array from the image.\n",
    "    img_array = np.array(f, dtype = np.uint8)\n",
    "\n",
    "# This time, we also load the segmentation of the liver and potential tumors.\n",
    "with PIL.Image.open(\"../data/Clean_LiTS/train/segmentations/segmentation-10_livermask_337.png\") as f:\n",
    "    f = f.convert(\"L\")\n",
    "    liver = np.array(f, dtype = np.uint8)\n",
    "with PIL.Image.open(\"../data/Clean_LiTS/train/segmentations/segmentation-10_lesionmask_337.png\") as f:\n",
    "    f = f.convert(\"L\")\n",
    "    tumors = np.array(f, dtype = np.uint8)\n",
    "\n",
    "# We make what is called a meshgrid - they are a tool designed for exactly the\n",
    "# kind of plot that we are making right now. A meshgrid is essentially every\n",
    "# combination of x and y coordinates in our image.\n",
    "X, Y = np.meshgrid(np.arange(256), np.arange(256))\n",
    "plt.figure()\n",
    "# We show the image again, but since we only have one channel now,\n",
    "# we get to use colormaps, which look a lot nicer than regular grayscale images.\n",
    "plt.imshow(img_array, cmap = \"bone\")\n",
    "plt.xlim((0, 256))\n",
    "plt.ylim((0, 256))\n",
    "# We can draw the 'truth' into our image with the help of the countour function\n",
    "plt.contour(X, Y, liver, colors = \"g\", alpha = 0.25, linewidths = 0.5)\n",
    "plt.contour(X, Y, tumors, colors = \"r\", alpha = 0.25, linewidths = 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the image looks like, let's figure out how to give it to our GPU.\n",
    "\n",
    "PyTorch expects a very specific order of dimensions for its inputs: $B * C * H * W$, where $B$ is the number of images in a batch (images I work with in parallel), C is the number of channels it has (such as RGB), and H and W are height and width. opencv (the library that PIL is built on) orders them the other way around: $H * W * C$. Helpfully, PyTorch knows about PIL, and we can turn the PIL Image that we have seen before directly into a PyTorch tensor using a function called pil_to_tensor. As you can see, it also puts the dimensions in the right order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image as a PIL Image\n",
    "image = PIL.Image.open('../data/Clean_LiTS/train/volumes/volume-10_337.png')\n",
    "\n",
    "# Convert the PIL image to Torch tensor\n",
    "img_tensor = torchvision.transforms.functional.pil_to_tensor(image)\n",
    "\n",
    "# Print the shape of the original image, and the converted tensor\n",
    "print(np.array(image).shape)\n",
    "print(img_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All that is left now, is to push the image to the GPU, if I am so inclined:\n",
    "\n",
    "img_tensor = img_tensor.to(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.3: \"The recipe\"\n",
    "\n",
    "Now that we have an understanding of what kind of image we are loading, and how to load them properly, let's get to the core of the machine learning with neural networks. Below, you will see the basic recipe for training a neural network.\n",
    "\n",
    "In practice, only very few steps are necessary to train a neural network. The more sophisticated your training algorithm and the more complex your data, the more you will eventually move away from this recipe. Conceptually, however, the steps remain largely the same:\n",
    "\n",
    "- I) Take the input images and do some preprocessing to them. This includes things such as guaranteeing the images to all have the same shape, cutting off uninteresting parts of the image, or performing image augmentations like adding noise.\n",
    "- II) Feed them to the GPU.\n",
    "- III) Let the model make some predictions.\n",
    "- IV) Compute the loss function from the predictions and the ground truths. (\"How wrong were my predictions?\")\n",
    "- V) Derive the gradients of the model parameters with respect to the loss. (\"In which direction must my parameters move to decrease my loss and thereby improve earlier predictions?\")\n",
    "- VI) Move all model parameters into this direction for a certain distance. (\"Ask, how far must I go in this direction, then go.\")\n",
    "- VII) Repeat 1-6 until the predictions become good.\n",
    "- VIII) Occasionally validate your performance on previously unseen data to check whether they are good.\n",
    "- IX) Finally, evaluate the model on previously unseen data. This is the final result, and the thing reported in papers.\n",
    "\n",
    "For now, we will go through the recipe and get an understanding of what we do and why. Once we understand this, we can start replacing the ready-to-go code provided by PyTorch with our own code. If something does not work later on, it can always be good to go back to the recipe and try to see what the recipe does that you maybe don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example will actually train something, although it is not particularly sophisticated.\n",
    "# Try to execute it, and try to follow what each part of the code does!\n",
    "\n",
    "# 1) Imports\n",
    "\"\"\"\n",
    "First, we handle our imports. Typically we do this at the top of our\n",
    "program. If looking at the text starts bothering you, you are free to\n",
    "delete it, edit it, or click the little arrow next to the quotation\n",
    "marks to hide the text in a single line.\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "# We import some helper functions that we made, too. Later, you will\n",
    "# make these functions yourself.\n",
    "import sys\n",
    "sys.path.append(\"/Volumes/PortableSSD/MLCourse/Course_Materials\")\n",
    "import utility.utils as uu\n",
    "\n",
    "# We also check if CUDA (read: at least one GPU) is available\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) The Dataset\n",
    "\"\"\"\n",
    "PyTorch has specific requirements that datasets need to fulfill.\n",
    "A dataset is a class and it handles your data (surprise). In the\n",
    "next chapter, we will make our own, and we will discuss in more\n",
    "detail what actually needs to be done to replace one.\n",
    "\n",
    "For now, we will stick with a pre-existing one, called CIFAR10.\n",
    "CIFAR10 contains images of flowers, which we want to try and classify.\n",
    "\n",
    "(Since someone thought it would be a fantastic idea for the dataset to\n",
    "return PIL Images instead of tensors, we add a ToTensor transform. We\n",
    "will come back to transforms and how to use them later. For now, you\n",
    "don't have to concern yourself with that.)\n",
    "\n",
    "Finally, since we will want to gain an understanding of the actual\n",
    "performance we have reached, we will split our dataset into a train,\n",
    "validation, and test set, containing 80%, 10% and 10% of the data\n",
    "respectively.\n",
    "\"\"\"\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "dataset = torchvision.datasets.CIFAR10(\"../data/CIFAR10/\", download = True, transform = transforms)\n",
    "dl = len(dataset)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset = dataset, lengths = [int(0.8*dl), int(0.1*dl), int(0.1*dl)])\n",
    "\n",
    "# 3) The Dataloader\n",
    "\"\"\"\n",
    "A dataloader wraps a dataset. It does not do all that much.\n",
    "For the most part, it just grabs random data points from your dataset,\n",
    "glues the tensors together along the first dimension and returns them.\n",
    "We will discuss in more detail the options that the dataloader affords\n",
    "us, but we will not have to write our own.\n",
    "\n",
    "Let's quickly walk through what we are telling the dataloader:\n",
    "dataset - This is the dataset from the step before. We make one dataloader\n",
    "            for each of the subsets we have created.\n",
    "batch_size - How many images do we want our dataloader to give us at\n",
    "            once.\n",
    "num_workers - The dataloader outsources the loading of the data to a\n",
    "            number of processes to speed things up. We can select the\n",
    "            number of processes here. Specifying \"0\" means that the\n",
    "            main process will do all the loading. This is a bit slower\n",
    "            but sometimes more useful for debugging.\n",
    "shuffle - Whether we want to shuffle our dataset before loading. As a\n",
    "            general rule, you should always shuffle your dataset during\n",
    "            training so the neural network sees different combinations\n",
    "            of data.\n",
    "drop_last - Imagine you have 100 images. Your batch size is 32. You can\n",
    "            create 3 proper batches, which have a length of 32 along the\n",
    "            first dimension. Your final batch, before you start the next\n",
    "            epoch and go through your dataset again, will contain only 4\n",
    "            images. A lot of the time, we do not want such an incomplete\n",
    "            batch! Why this is the case, we will learn a little later.\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_set,\n",
    "    batch_size = batch_size, \n",
    "    num_workers = 8, \n",
    "    shuffle = True, \n",
    "    drop_last = True\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = val_set,\n",
    "    batch_size = batch_size, \n",
    "    num_workers = 0, \n",
    "    shuffle = False, \n",
    "    drop_last = False\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_set,\n",
    "    batch_size = batch_size, \n",
    "    num_workers = 0, \n",
    "    shuffle = False, \n",
    "    drop_last = False\n",
    "    )\n",
    "\n",
    "# 4) The Model\n",
    "\"\"\"\n",
    "If machine learning is a meal, then the model is the meat.\n",
    "The model contorts and compresses the input images into a low-dimensional\n",
    "space, according to its architecture and current weights. It makes some\n",
    "prediction for the input images, which will later be evaluated. The model\n",
    "is later corrected according to this evaluation. Most of the work later\n",
    "during the course will be to create our own models, and recreate the most\n",
    "successful and inflential ones from the history of the field.\n",
    "\n",
    "For the moment, we will simply pick up a pre-existing model and not make\n",
    "one ourselves. The only thing we change is the final layer of the model,\n",
    "since the model was originally designed for different data. Don't concern\n",
    "yourself with that last step for now, we will come back to this.\n",
    "\"\"\"\n",
    "model = torchvision.models.resnet18(pretrained = True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "# 5) The Loss function\n",
    "\"\"\"\n",
    "After the model has made a prediction, we want to know, how good it was.\n",
    "In order for the model to be able to benefit from this representation of\n",
    "its quality, said function needs to fulfill several criteria: It has to\n",
    "be differentiable (almost) everywhere, so we can derive gradients for\n",
    "our model parameters from it and it needs to return lower values, the\n",
    "better the predictions and targets match up.\n",
    "\n",
    "Mathematically, we compute the loss function, a measure of how bad our\n",
    "predictions for the current data were. Later, we optimize our network\n",
    "parameters by computing the gradient of the loss function with respect\n",
    "to each specific parameter. This step is fully automated in PyTorch.\n",
    "\n",
    "For any set of modules which have a forward function that performed\n",
    "differentiable operations, the '.backward()' function will be created\n",
    "by PyTorch - we do not have to calculate anything manually.\n",
    "\n",
    "Writing such a loss function is comparatively easy, and we will be doing\n",
    "so much later during the course. For now, we will use an out-of-the-box\n",
    "loss function that PyTorch provides, called CrossEntropyLoss. You can\n",
    "find the exact formula of how predictions are \"rated\" here:\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\"\"\"\n",
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 6) The Optimizer\n",
    "\"\"\"\n",
    "This is where a large part of the magic happens. The optimizer has access\n",
    "to all of a model's parameters. When each parameter has figured out in\n",
    "which 'direction' the greatest improvement to the earlier predictions was\n",
    "to be found, the optimizer figures out, how far to actually move the\n",
    "parameters in this direction.\n",
    "\n",
    "(Good) optimizers are quite complicated to write, and few people fully\n",
    "understand the complex math involved in guaranteeing convergence and\n",
    "stability of the learning process. We may look at a couple different ones\n",
    "and give some overview of how they operate. However, we will not be making\n",
    "our own.\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-4, weight_decay = 1e-2)\n",
    "\n",
    "# 7) The Training Loop\n",
    "\"\"\"\n",
    "Now it's time to stick all of it together.\n",
    "We follow steps I-IX from the start of the chapter.\n",
    "\"\"\"\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # I) Grab my data\n",
    "    for step, (data, targets) in enumerate(train_loader):\n",
    "\n",
    "        # This command is a peculiarity of PyTorch.\n",
    "        # PyTorch accumulates gradients of parameters instead of overwriting\n",
    "        # them when new predictions are made. This is a useful feature, but\n",
    "        # most of the time, people do not use it. zero_grad() manually resets\n",
    "        # this accumulation process.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # II) Put it onto the GPU.\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # III) Make some predictions.\n",
    "        predictions = model(data)\n",
    "\n",
    "        # IV) How wrong were our predictions?\n",
    "        loss = loss_criterion(predictions, targets)\n",
    "        \n",
    "        # At this point it's also useful to print out performance indicators.\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\\t Step [{step+1}/{len(train_set)//batch_size}]\\t Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # V) In which direction do we have to go to make them better?\n",
    "        loss.backward()\n",
    "\n",
    "        # VI) How far do I have to go in this direction?\n",
    "        # Once I know it, move the parameters accordingly.\n",
    "        optimizer.step()\n",
    "\n",
    "        # VII) Repeat.\n",
    "    \n",
    "    # VIII) Let's occasionally validate our model's performance on unseen data.\n",
    "    if epoch % 5 == 0 and not epoch == 0:\n",
    "    \n",
    "        # We first tell our model to not try and train parameters for now.\n",
    "        model.eval()\n",
    "\n",
    "        # We also tell PyTorch to not collect any gradients for the time being.\n",
    "        with torch.no_grad():\n",
    "\n",
    "            hits = 0\n",
    "            losses = []\n",
    "            batch_sizes = []\n",
    "\n",
    "            # This time, we grab the validation data our model has not seen before.\n",
    "            for step, (data, targets) in enumerate(val_loader):\n",
    "\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                predictions = model(data)\n",
    "                loss = loss_criterion(predictions, targets)\n",
    "                losses.append(loss.item())\n",
    "                batch_sizes.append(data.size()[0])\n",
    "\n",
    "                # In the hope that our performance during validation is indicative\n",
    "                # of our performance on the test set (which is usually reported in\n",
    "                # papers and challenges), let's measure our actual accuracy.\n",
    "                # First, we convert our predictions from a tensor of dimensions\n",
    "                # N x C (batch size x classes) to one of dimension N.\n",
    "                class_predictions = torch.argmax(predictions, dim = 1).flatten()\n",
    "                # Then, we count the number of correct predictions.\n",
    "                hits = hits + sum([1 if cp == t else 0 for cp, t in zip(class_predictions, targets)])\n",
    "\n",
    "            accuracy = hits / len(val_set)\n",
    "            avg_loss = sum([l * bs for l, bs in zip(losses, batch_sizes)]) / sum(batch_sizes)\n",
    "            print(f\"Epoch: {epoch},\\t Validation Loss: {avg_loss:.4f},\\t Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # After we are done validating, let's not forget to go back to storing gradients!\n",
    "        model.train()\n",
    "\n",
    "# IX) Let's check our final performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwhelmed? That is very understandable. Not overwhelmed? Even better!\n",
    "\n",
    "For now, before we break everything apart and look at the innards, let's first try to get a little bit of a handle on things. See if you can answer the following questions, or, more to the point, if you can edit the code in question successfully.\n",
    "\n",
    "1. Try to complete step IX) on your own. It should look almost the same as the validation.\n",
    "2. Try to replace the dataset (for example with CIFAR100) and see what happens. Edit the code so that CIFAR100 trains successfully for a little while.\n",
    "3. Try to replace the model with another pre-existing model (maybe another ResNet, or maybe another model entirely) and see what happens. Do you see where it breaks down? Try to adapt the code to successfully use another model.\n",
    "4. Try running the model on the CPU instead of the GPU.\n",
    "\n",
    "You can edit the recipe above, or copy it over to below and start editing there. You are welcome to throw out any and all parts if you want to test something. *If there is any questions at this point, always ask - no questions are stupid!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions\n",
    "\n",
    "# == Task 1 ==\n",
    "# The solution here can simply be appended at the end of the code that already exists.\n",
    "\n",
    "# First, disable model updates again.\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient collecting for the moment.\n",
    "with torch.no_grad():\n",
    "\n",
    "    hits = 0\n",
    "    losses = []\n",
    "    batch_sizes = []\n",
    "\n",
    "    # This time, we grab the test data our model has not seen before.\n",
    "    for step, (data, targets) in enumerate(test_loader):\n",
    "\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        predictions = model(data)\n",
    "        loss = loss_criterion(predictions, targets)\n",
    "        losses.append(loss.item())\n",
    "        batch_sizes.append(data.size()[0])\n",
    "        class_predictions = torch.argmax(predictions, dim=1).flatten()\n",
    "        hits = hits + sum([1 if cp == t else 0 for cp, t in zip(class_predictions, targets)])\n",
    "\n",
    "    accuracy = hits / len(test_set)\n",
    "    avg_loss = sum([l * bs for l, bs in zip(losses, batch_sizes)]) / sum(batch_sizes)\n",
    "    print(f\"Final testing - Test Loss: {avg_loss:.4f},\\t Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# == Task 2 ==\n",
    "# All that needs to be done is to \n",
    "# 1) replace the dataset's name with CIFAR100,\n",
    "# 2) and change the number of output nodes in model.fc to 100.\n",
    "\n",
    "# == Task 3 ==\n",
    "# Any other ResNet should work just fine. Other models should usually not.\n",
    "# The reason is that the pre-existing models all use their own names for\n",
    "# the different layers. Hence, we need to find out the name of the final\n",
    "# layer.\n",
    "\n",
    "# == Task 4 ==\n",
    "# Exchange the line\n",
    "#device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# with\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save our model to the disk like so ('../models' means 'go back 1 directory, then into 'models'):\n",
    "def save_model(name, model):\n",
    "    loc = os.path.join(\"../models\", name)\n",
    "    os.makedirs(\"../models\", exist_ok = True)\n",
    "\n",
    "    # To save a DataParallel model generically, save the model.module.state_dict().\n",
    "    # This way, you have the flexibility to load the model any way you want to any device you want.\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(), loc)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), loc)\n",
    "\n",
    "save_model(\"MLC_1.tar\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connect-drmDkA6-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ee31484d7275e6b80e761663adfd4fd899bcbf00411646d42eac6f446beb273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
